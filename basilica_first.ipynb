{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install basilica\n",
    "import basilica\n",
    "conn = basilica.Connection(YOUR_KEY)\n",
    "embedding = conn.embed_sentence('hey this is a cool tweet', model='twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install basilica\n",
    "import basilica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO NOT EXPOSE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = '7f8e7b80-be40-8936-1a61-cef3d1926786'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = basilica.Connection(API_KEY)\n",
    "embedding = conn.embed_sentence('hey, super-cool tweet!', model='twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one is fake \n",
    "Nietzsche_0 = \"\"\"Many are stubborn in pursuit of the path they have taken, few in pursuit of the goal.\"\"\"\n",
    "\n",
    "Nietzsche_1 = \"\"\"Whoever fights monsters should see to it that in the process he does not become a monster. \n",
    "And if you gaze long enough into an abyss, the abyss will gaze back into you.\"\"\"\n",
    "\n",
    "Nietzsche_2 = \"\"\"The best author will be the one who is ashamed to become a writer.\"\"\"\n",
    "\n",
    "Nietzsche_3 = \"\"\"Woman was God's second mistake.\"\"\"\n",
    "\n",
    "Nietzsche_4 = \"\"\"Many are stubborn in pursuit of the path they have chosen, few in pursuit of the goal.\"\"\"\n",
    "\n",
    "Nietzsche_quotes = [Nietzsche_0, Nietzsche_1, Nietzsche_2, Nietzsche_3, Nietzsche_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import basilica\n",
    "sentences = Nietzsche_quotes\n",
    "with basilica.Connection(API_KEY) as c:\n",
    "    embeddings = list(c.embed_sentences(sentences))\n",
    "# print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,6):\n",
    "#     print(f\"Nietzsche_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1374542495567791\n",
      "0.12171451277603651\n",
      "0.002116208769955774\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "print(spatial.distance.cosine(embeddings[0], embeddings[1]))\n",
    "print(spatial.distance.cosine(embeddings[0], embeddings[2]))\n",
    "print(spatial.distance.cosine(embeddings[0], embeddings[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with basilica.Connection(API_KEY) as c:\n",
    "#     embedding = c.embed_image_file('./cats_dogs_demo/images/dog.1.jpg')\n",
    "#     print(len(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import zip\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIR = '/tmp/basilica-embeddings/'\n",
    "if not os.path.exists(EMB_DIR):\n",
    "    os.mkdir(EMB_DIR)\n",
    "\n",
    "IMG_DIR = './cats_dogs_demo/images/'\n",
    "# API_KEY = '7f8e7b80-be40-8936-1a61-cef3d1926786'\n",
    "\n",
    "# uncomment to run - it is long\n",
    "\n",
    "# with basilica.Connection(API_KEY) as c:\n",
    "#     filenames = os.listdir(IMG_DIR)\n",
    "#     embeddings = c.embed_image_files(IMG_DIR + f for f in filenames)\n",
    "#     for filename, embedding in zip(filenames, embeddings):\n",
    "#         with open(EMB_DIR + filename + '.emb', 'w') as f:\n",
    "#             f.write(json.dumps(embedding))\n",
    "#             print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier\n",
    "Let's train a classifier that distinguishes cat pictures from dog pictures, using sklearn.linear_model.LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIR = './basilica-embeddings/'\n",
    "files = [f for f in os.listdir(EMB_DIR)]\n",
    "random.shuffle(files)\n",
    "\n",
    "train_size = int(len(files)*0.8)\n",
    "# train_size = 2400\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.zeros((train_size, 2048))\n",
    "x_test = np.zeros((len(files)-train_size, 2048))\n",
    "\n",
    "y_train = np.zeros(train_size, dtype=int)\n",
    "y_test = np.zeros(len(files)-train_size, dtype=int)\n",
    "\n",
    "for i in range(train_size):\n",
    "    filename = files[i]\n",
    "    with open(EMB_DIR + filename, 'r') as f:\n",
    "        x_train[i] = json.load(f)\n",
    "        y_train[i] = (0 if re.match('.*cat.*', filename) else 1)\n",
    "\n",
    "for i in range(len(files) - train_size):\n",
    "    filename = files[train_size+i]\n",
    "    with open(EMB_DIR + filename, 'r') as f:\n",
    "        x_test[i] = json.load(f)\n",
    "        y_test[i] = (0 if re.match('.*cat.*', filename) else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = sklearn.preprocessing.normalize(x_train)\n",
    "x_test = sklearn.preprocessing.normalize(x_test)\n",
    "\n",
    "model = sklearn.linear_model.LogisticRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy, right? Let's see how well it did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.988\n",
      "Test accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy: %.3f' % model.score(x_train, y_train))\n",
    "print('Test accuracy: %.3f' % model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat.406.jpg.emb: 0.23\n",
      "cat.944.jpg.emb: 0.25\n",
      "cat.201.jpg.emb: 0.31\n"
     ]
    }
   ],
   "source": [
    "test_proba = model.predict_proba(x_test)\n",
    "collected = zip(files[train_size:], y_test, test_proba)\n",
    "probabilities = [(pred[y], f) for f, y, pred in collected]\n",
    "probabilities.sort()\n",
    "for prob, filename in probabilities[:3]:\n",
    "    print('%s: %.2f' % (filename, prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import basilica\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sklearn.decomposition\n",
    "import sklearn.neighbors\n",
    "import sklearn.preprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load up the embeddings for all of the dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMB_DIR = '/tmp/basilica-embeddings/'\n",
    "files = [f for f in os.listdir(EMB_DIR) if re.match('.*dog.*', f)]\n",
    "random.shuffle(files)\n",
    "signatures = np.zeros((len(files), 2048))\n",
    "for i, filename in enumerate(files):\n",
    "    with open(EMB_DIR + filename, 'r') as f:\n",
    "        signatures[i] = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's fit a nearest neighbors model. The number of dimensions you want for nearest neighbors search is usually much smaller than the number you want for classification, so we're going to PCA down to 200 dimensions first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler(with_std=False)\n",
    "\n",
    "pca = sklearn.decomposition.PCA(n_components=200, whiten=True)\n",
    "\n",
    "signatures = sklearn.preprocessing.normalize(signatures)\n",
    "\n",
    "signatures = scaler.fit_transform(signatures)\n",
    "signatures = pca.fit_transform(signatures)\n",
    "signatures = sklearn.preprocessing.normalize(signatures)\n",
    "\n",
    "nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=4).fit(signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog.1.jpg.emb dog.603.jpg.emb dog.262.jpg.emb dog.1291.jpg.emb\n",
      "dog.2.jpg.emb dog.334.jpg.emb dog.849.jpg.emb dog.230.jpg.emb\n",
      "dog.3.jpg.emb dog.1157.jpg.emb dog.607.jpg.emb dog.988.jpg.emb\n"
     ]
    }
   ],
   "source": [
    "# IMG_DIR = 'images/'\n",
    "target_files = ['dog.1.jpg', 'dog.2.jpg', 'dog.3.jpg']\n",
    "API_KEY = '7f8e7b80-be40-8936-1a61-cef3d1926786'\n",
    "with basilica.Connection(API_KEY) as c:\n",
    "    targets = np.array(list(c.embed_image_files(IMG_DIR + f for f in target_files)))\n",
    "\n",
    "targets = sklearn.preprocessing.normalize(targets)\n",
    "targets = scaler.transform(targets)\n",
    "targets = pca.transform(targets)\n",
    "targets = sklearn.preprocessing.normalize(targets)\n",
    "\n",
    "_, all_indices = nbrs.kneighbors(targets)\n",
    "for indices in all_indices:\n",
    "    print(' '.join(files[i] for i in indices))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
